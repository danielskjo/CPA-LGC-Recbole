{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239d2a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CSE\\anaconda3\\envs\\GL\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import networkx as nx\n",
    "import json\n",
    "import logging\n",
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger\n",
    "from recbole.model.general_recommender import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "733f9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from recbole.model.abstract_recommender import GeneralRecommender\n",
    "from recbole.model.init import xavier_uniform_initialization\n",
    "from recbole.model.loss import BPRLoss, EmbLoss\n",
    "from recbole.utils import InputType\n",
    "\n",
    "\n",
    "class CPALGC(GeneralRecommender):\n",
    "    r\"\"\"LightGCN is a GCN-based recommender model.\n",
    "\n",
    "    LightGCN includes only the most essential component in GCN — neighborhood aggregation — for\n",
    "    collaborative filtering. Specifically, LightGCN learns user and item embeddings by linearly \n",
    "    propagating them on the user-item interaction graph, and uses the weighted sum of the embeddings\n",
    "    learned at all layers as the final embedding.\n",
    "\n",
    "    We implement the model following the original author with a pairwise training mode.\n",
    "    \"\"\"\n",
    "    input_type = InputType.PAIRWISE\n",
    "\n",
    "    def __init__(self, config, dataset, n_cri):\n",
    "        super(CPALGC, self).__init__(config, dataset)\n",
    "\n",
    "        # load dataset info\n",
    "        self.interaction_matrix = dataset.inter_matrix(form='coo').astype(np.float32)\n",
    "        self.cri_idx_shift = int((self.n_items)/n_cri) # should be replaced with variable later\n",
    "        self.n_cri = n_cri\n",
    "\n",
    "        # load parameters info\n",
    "        self.latent_dim = config['embedding_size']  # int type:the embedding size of lightGCN\n",
    "        self.n_layers = config['n_layers']  # int type:the layer num of lightGCN\n",
    "        self.reg_weight = config['reg_weight']  # float32 type: the weight decay for l2 normalization\n",
    "\n",
    "        # define layers and loss\n",
    "        self.user_embedding = torch.nn.Embedding(num_embeddings=self.n_users, embedding_dim=self.latent_dim)\n",
    "        self.item_embedding = torch.nn.Embedding(num_embeddings=self.n_items, embedding_dim=self.latent_dim)\n",
    "        self.cri_user_embedding = torch.nn.Embedding(num_embeddings=self.n_users, embedding_dim=self.latent_dim)\n",
    "        self.cri_embedding_item = torch.zeros((self.n_items, self.latent_dim), device = config['device'])\n",
    "\n",
    "        self.norm = PairNorm('PN', scale = 1)\n",
    "\n",
    "        self.__init_criteria_weight()\n",
    "\n",
    "    \n",
    "        self.mf_loss = BPRLoss()\n",
    "        self.reg_loss = EmbLoss()\n",
    "\n",
    "        # storage variables for full sort evaluation acceleration\n",
    "        self.restore_user_e = None\n",
    "        self.restore_item_e = None\n",
    "\n",
    "        # generate intermediate data\n",
    "        self.norm_adj_matrix = self.get_norm_adj_mat_2().to(self.device)\n",
    "\n",
    "        # parameters initialization\n",
    "        self.apply(xavier_uniform_initialization)\n",
    "\n",
    "    def __init_criteria_weight(self):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.cri_emb_nograd = torch.zeros((self.n_cri, self.latent_dim))\n",
    "\n",
    "        #nn.init.normal(self.cri_emb_nograd, std=0.1)\n",
    "        torch.nn.init.xavier_uniform_(self.cri_emb_nograd)\n",
    "        \n",
    "        self.cri_emb_nograd[0] = torch.zeros(self.latent_dim)\n",
    "\n",
    "        for i in range(self.n_items):\n",
    "            if i // self.cri_idx_shift == 0:\n",
    "                pass\n",
    "            elif i // self.cri_idx_shift >= self.n_cri:\n",
    "                self.cri_embedding_item[i] = self.cri_emb_nograd[self.n_cri-1]\n",
    "            else:\n",
    "                self.cri_embedding_item[i] = self.cri_emb_nograd[i // self.cri_idx_shift]\n",
    "                 \n",
    "            \n",
    "    def get_norm_adj_mat(self):\n",
    "        r\"\"\"Get the normalized interaction matrix of users and items.\n",
    "\n",
    "        Construct the square matrix from the training data and normalize it\n",
    "        using the laplace matrix.\n",
    "\n",
    "        .. math::\n",
    "            A_{hat} = D^{-0.5} \\times A \\times D^{-0.5}\n",
    "\n",
    "        Returns:\n",
    "            Sparse tensor of the normalized interaction matrix.\n",
    "        \"\"\"\n",
    "        # build adj matrix\n",
    "        A = sp.dok_matrix((self.n_users + self.n_items, self.n_users + self.n_items), dtype=np.float32)\n",
    "        inter_M = self.interaction_matrix\n",
    "        inter_M_t = self.interaction_matrix.transpose()\n",
    "        data_dict = dict(zip(zip(inter_M.row, inter_M.col + self.n_users), [1] * inter_M.nnz))\n",
    "        data_dict.update(dict(zip(zip(inter_M_t.row + self.n_users, inter_M_t.col), [1] * inter_M_t.nnz)))\n",
    "        A._update(data_dict)\n",
    "        # norm adj matrix\n",
    "        sumArr = (A > 0).sum(axis=1)\n",
    "        # add epsilon to avoid divide by zero Warning\n",
    "        diag = np.array(sumArr.flatten())[0] + 1e-7\n",
    "        diag = np.power(diag, -0.5)\n",
    "        D = sp.diags(diag)\n",
    "        L = D * A * D\n",
    "        # covert norm_adj matrix to tensor\n",
    "        L = sp.coo_matrix(L)\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        i = torch.LongTensor([row, col])\n",
    "        data = torch.FloatTensor(L.data)\n",
    "        SparseL = torch.sparse.FloatTensor(i, data, torch.Size(L.shape))\n",
    "        return SparseL\n",
    "            \n",
    "    def get_norm_adj_mat_2(self):\n",
    "        r\"\"\"Get the normalized interaction matrix of users and items.\n",
    "\n",
    "        Construct the square matrix from the training data and normalize it\n",
    "        using the laplace matrix.\n",
    "\n",
    "        .. math::\n",
    "            A_{hat} = D^{-0.5} \\times A \\times D^{-0.5}\n",
    "\n",
    "        Returns:\n",
    "            Sparse tensor of the normalized interaction matrix.\n",
    "        \"\"\"\n",
    "        alpha = 1.5\n",
    "\n",
    "        # build adj matrix\n",
    "        A = sp.dok_matrix((self.n_users + self.n_items, self.n_users + self.n_items), dtype=np.float32)\n",
    "        inter_M = self.interaction_matrix\n",
    "        inter_M_t = self.interaction_matrix.transpose()\n",
    "        data_dict = dict(zip(zip(inter_M.row, inter_M.col + self.n_users), [alpha for _ in range(self.cri_idx_shift)] + [1] * inter_M.nnz))\n",
    "        data_dict.update(dict(zip(zip(inter_M_t.row + self.n_users, inter_M_t.col), [alpha for _ in range(self.cri_idx_shift)] + [1] * inter_M.nnz)))\n",
    "        A._update(data_dict)\n",
    "        # norm adj matrix\n",
    "        sumArr = (A > 0).sum(axis=1)\n",
    "        # add epsilon to avoid divide by zero Warning\n",
    "        diag = np.array(sumArr.flatten())[0] + 1e-7\n",
    "        diag = np.power(diag, -0.5)\n",
    "        D = sp.diags(diag)\n",
    "        L = D * A * D\n",
    "        # covert norm_adj matrix to tensor\n",
    "        L = sp.coo_matrix(L)\n",
    "        row = L.row\n",
    "        col = L.col\n",
    "        i = torch.LongTensor([row, col])\n",
    "        data = torch.FloatTensor(L.data)\n",
    "        SparseL = torch.sparse.FloatTensor(i, data, torch.Size(L.shape))\n",
    "        return SparseL\n",
    "\n",
    "    def get_ego_embeddings(self):\n",
    "        r\"\"\"Get the embedding of users and items and combine to an embedding matrix.\n",
    "\n",
    "        Returns:\n",
    "            Tensor of the embedding matrix. Shape of [n_items+n_users, embedding_dim]\n",
    "        \"\"\"\n",
    "        user_embeddings = self.user_embedding.weight\n",
    "        item_embeddings = self.item_embedding.weight\n",
    "        ego_embeddings = torch.cat([user_embeddings, item_embeddings], dim=0)\n",
    "\n",
    "        cri_user_embeddings = self.cri_user_embedding.weight\n",
    "        cri_item_embeddings = self.cri_embedding_item\n",
    "        cri_ego_embeddings = torch.cat([cri_user_embeddings, cri_item_embeddings], dim=0)\n",
    "        return ego_embeddings, cri_ego_embeddings \n",
    "\n",
    "    def forward(self):\n",
    "        all_embeddings, cri_all_embeddings = self.get_ego_embeddings()\n",
    "        all_embeddings = self.norm(all_embeddings)\n",
    "        cri_all_embeddings = self.norm(cri_all_embeddings)\n",
    "        embeddings_list = [all_embeddings]\n",
    "        cri_embeddings_list = [cri_all_embeddings]\n",
    "\n",
    "        for layer_idx in range(self.n_layers):\n",
    "            all_embeddings = torch.sparse.mm(self.norm_adj_matrix, all_embeddings)\n",
    "            all_embeddings = self.norm(all_embeddings)\n",
    "            embeddings_list.append(all_embeddings)\n",
    "\n",
    "        for layer_idx in range(self.n_layers):\n",
    "            cri_all_embeddings = torch.sparse.mm(self.norm_adj_matrix, cri_all_embeddings)\n",
    "            cri_all_embeddings = self.norm(cri_all_embeddings)\n",
    "            cri_embeddings_list.append(cri_all_embeddings)\n",
    "\n",
    "        lightgcn_all_embeddings = torch.stack(embeddings_list, dim=1)\n",
    "        lightgcn_all_embeddings = torch.mean(lightgcn_all_embeddings, dim=1)\n",
    "\n",
    "        lightgcn_cri_embeddings = torch.stack(cri_embeddings_list, dim=1)\n",
    "        lightgcn_cri_embeddings = torch.mean(lightgcn_cri_embeddings, dim=1)\n",
    "\n",
    "        lightgcn_all_embeddings = self.norm(lightgcn_all_embeddings)\n",
    "        lightgcn_cri_embeddings = self.norm(lightgcn_cri_embeddings)\n",
    "\n",
    "        lightgcn_all_embeddings = torch.cat([lightgcn_all_embeddings, lightgcn_cri_embeddings ], dim = 1)\n",
    "\n",
    "        user_all_embeddings, item_all_embeddings = torch.split(lightgcn_all_embeddings, [self.n_users, self.n_items])\n",
    "\n",
    "        return user_all_embeddings, item_all_embeddings\n",
    "\n",
    "\n",
    "    def calculate_loss(self, interaction):\n",
    "        # clear the storage variable when training\n",
    "        if self.restore_user_e is not None or self.restore_item_e is not None:\n",
    "            self.restore_user_e, self.restore_item_e = None, None\n",
    "\n",
    "        user = interaction[self.USER_ID]\n",
    "        pos_item = interaction[self.ITEM_ID]\n",
    "        neg_item = interaction[self.NEG_ITEM_ID]\n",
    "\n",
    "        user_all_embeddings, item_all_embeddings = self.forward()\n",
    "        u_embeddings = user_all_embeddings[user]\n",
    "        pos_embeddings = item_all_embeddings[pos_item]\n",
    "        neg_embeddings = item_all_embeddings[neg_item]\n",
    "\n",
    "        # calculate BPR Loss\n",
    "        pos_scores = torch.mul(u_embeddings, pos_embeddings).sum(dim=1)\n",
    "        neg_scores = torch.mul(u_embeddings, neg_embeddings).sum(dim=1)\n",
    "        mf_loss = self.mf_loss(pos_scores, neg_scores)\n",
    "\n",
    "        # calculate reg Loss\n",
    "        u_ego_embeddings = self.user_embedding(user)\n",
    "        pos_ego_embeddings = self.item_embedding(pos_item)\n",
    "        neg_ego_embeddings = self.item_embedding(neg_item)\n",
    "\n",
    "        reg_loss = self.reg_loss(u_ego_embeddings, pos_ego_embeddings, neg_ego_embeddings)\n",
    "        loss = mf_loss + self.reg_weight * reg_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def predict(self, interaction):\n",
    "        user = interaction[self.USER_ID]\n",
    "        item = interaction[self.ITEM_ID]\n",
    "\n",
    "        user_all_embeddings, item_all_embeddings = self.forward()\n",
    "\n",
    "        u_embeddings = user_all_embeddings[user]\n",
    "        i_embeddings = item_all_embeddings[item]\n",
    "        scores = torch.mul(u_embeddings, i_embeddings).sum(dim=1)\n",
    "        return scores\n",
    "\n",
    "    def full_sort_predict(self, interaction):\n",
    "        user = interaction[self.USER_ID]\n",
    "        if self.restore_user_e is None or self.restore_item_e is None:\n",
    "            self.restore_user_e, self.restore_item_e = self.forward()\n",
    "        # get user embedding from storage variable\n",
    "        u_embeddings = self.restore_user_e[user]\n",
    "        # dot with all item embedding to accelerate\n",
    "        scores = torch.matmul(u_embeddings, self.restore_item_e.transpose(0, 1))\n",
    "        # We only consider overall interactions.\n",
    "        scores[:,int(self.n_items/self.n_cri):] = -np.inf\n",
    "\n",
    "        return scores.view(-1)\n",
    "\n",
    "\n",
    "\n",
    "class PairNorm(torch.nn.Module):\n",
    "    def __init__(self, mode='PN', scale=1):\n",
    "        \"\"\"\n",
    "            mode:\n",
    "              'None' : No normalization \n",
    "              'PN'   : Original version\n",
    "              'PN-SI'  : Scale-Individually version\n",
    "              'PN-SCS' : Scale-and-Center-Simultaneously version\n",
    "           \n",
    "            ('SCS'-mode is not in the paper but we found it works well in practice, \n",
    "              especially for GCN and GAT.)\n",
    "            PairNorm is typically used after each graph convolution operation. \n",
    "        \"\"\"\n",
    "        assert mode in ['None', 'PN',  'PN-SI', 'PN-SCS']\n",
    "        super(PairNorm, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.scale = scale\n",
    "\n",
    "        # Scale can be set based on origina data, and also the current feature lengths.\n",
    "        # We leave the experiments to future. A good pool we used for choosing scale:\n",
    "        # [0.1, 1, 10, 50, 100]\n",
    "                \n",
    "    def forward(self, x):\n",
    "        if self.mode == 'None':\n",
    "            return x\n",
    "        \n",
    "        col_mean = x.mean(dim=0)      \n",
    "        if self.mode == 'PN':\n",
    "            x = x - col_mean\n",
    "            rownorm_mean = (1e-6 + x.pow(2).sum(dim=1).mean()).sqrt() \n",
    "            x = self.scale * x / rownorm_mean\n",
    "\n",
    "        if self.mode == 'PN-SI':\n",
    "            x = x - col_mean\n",
    "            rownorm_individual = (1e-6 + x.pow(2).sum(dim=1, keepdim=True)).sqrt()\n",
    "            x = self.scale * x / rownorm_individual\n",
    "\n",
    "        if self.mode == 'PN-SCS':\n",
    "            rownorm_individual = (1e-6 + x.pow(2).sum(dim=1, keepdim=True)).sqrt()\n",
    "            x = self.scale * x / rownorm_individual - col_mean\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3d748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'TA5'\n",
    "ncri_table = {'TA5':8, 'YM5':5, 'RB5':5, 'RA5':5, 'YP5':4}\n",
    "n_cri = ncri_table[dataset_name]\n",
    "epoch = 10\n",
    "confg_dataset = {'benchmark_filename' : ['tr','val','ts']}\n",
    "parameter_dict = {\n",
    "    'benchmark_filename' : ['tr','val','ts'],\n",
    "    'data_path': '',\n",
    "    'seed': 2021,\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'user_inter_num_interval': \"[0,inf)\",\n",
    "    'item_inter_num_interval': \"[0,inf)\",\n",
    "    'load_col': {'inter': ['user_id', 'item_id']},\n",
    "    'neg_sampling': None,\n",
    "    'epochs': epoch,\n",
    "    'metrics':['Precision', 'Recall', 'NDCG'],\n",
    "    'split_ratio' : [0.7,0.1,0.2],\n",
    "    'topk':[5,10],\n",
    "    'device': torch.device('cuda'),\n",
    "    'embedding_size' : 64, \n",
    "    'n_layers' : 3,\n",
    "    'learning_rate' : 1e-3,\n",
    "    'reg_weight' : 1e-2,\n",
    "}\n",
    "\n",
    "config = Config(model='CPALGC', dataset=dataset_name, config_dict=parameter_dict)\n",
    "\n",
    "# init random seed\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "# logger initialization\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "# Create handlers\n",
    "c_handler = logging.StreamHandler()\n",
    "c_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(c_handler)\n",
    "\n",
    "\n",
    "# Dataset preparation\n",
    "datasets = create_dataset(config)\n",
    "\n",
    "# dataset splitting \n",
    "train_data, valid_data, test_data = data_preparation(config, datasets)\n",
    "\n",
    "# Model and learning,\n",
    "# model loading and initialization\n",
    "model = CPALGC(config, train_data.dataset, n_cri).to(config['device'])\n",
    "\n",
    "# trainer loading and initialization\n",
    "trainer = Trainer(config, model)\n",
    "\n",
    "# model training \n",
    "best_valid_score, best_valid_result = trainer.fit(train_data)\n",
    "\n",
    "# Evaluation\n",
    "results = trainer.evaluate(test_data)\n",
    "logger.info(results)\n",
    "\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "01d56e4f5b40df52e727cd0d9a997c21605191b2182136b742c013fa2d2e70ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
